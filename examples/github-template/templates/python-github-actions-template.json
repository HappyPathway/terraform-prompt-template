{
  "readme_content": "```markdown\n# smart-invest\n**Organization:** HappyPathway\n\n## 1. Overview\n\n`smart-invest` is a Python-based application designed for automated analysis of trade and investment data. It fetches data from various public APIs and databases, leverages AI (Gemini via PydanticAI) and Google Search for insights and data enrichment, predicts market patterns, and generates daily PDF reports. These reports, which include a self-assessment of past prediction accuracy, are then emailed to subscribers. The entire process is orchestrated to run as a scheduled cron job using GitHub Actions, with data persistence managed via SQLite and Google Cloud Storage (GCS).\n\n## 2. Features\n\n- **Automated Data Ingestion:** Fetches financial data from configurable public APIs and databases.\n- **AI-Powered Analysis:** Uses PydanticAI to interact with Gemini and Google Search for advanced data analysis and insight generation.\n- **Pattern Prediction:** Implements models to predict potential investment patterns and trends.\n- **Self-Assessment & History Tracking:** Records investment predictions, compares them against actual outcomes, and grades its own accuracy over time.\n- **PDF Reporting:** Generates comprehensive daily PDF reports summarizing findings, predictions, and self-assessment scores.\n- **Email Notifications:** Distributes PDF reports to a list of subscribers.\n- **Scheduled Execution:** Runs automatically on a configurable schedule (e.g., daily) via GitHub Actions.\n- **Persistent Storage:** Utilizes SQLite for local/intermediate data storage and Google Cloud Storage (GCS) for long-term backup and retrieval of data and reports.\n- **Modular Architecture:** Designed with distinct modules for different functionalities (data fetching, analysis, prediction, reporting, etc.).\n\n## 3. Architecture\n\nThe application follows a modular, pipeline-like architecture orchestrated by a main script run via GitHub Actions:\n\n1.  **Data Ingestion Agent:** Fetches raw data from specified public APIs (e.g., financial market data, news APIs).\n2.  **Data Processing & Enrichment Agent:** Cleans, transforms, and enriches the data. This agent utilizes PydanticAI to query Gemini and Google Search for contextual information, sentiment analysis, or relevant news.\n3.  **Pattern Prediction Agent:** Applies statistical models or machine learning algorithms to the processed data to identify potential patterns or make predictions.\n4.  **Prediction Storage & Evaluation Agent:** Stores new predictions in the SQLite database. Retrieves past predictions and compares them with newly fetched actual market data to calculate an accuracy score.\n5.  **Reporting Agent:** Compiles all information (current analysis, new predictions, past prediction accuracy) into a structured PDF report (likely using WeasyPrint from an HTML template).\n6.  **Notification Agent:** Emails the generated PDF report to a list of subscribers.\n7.  **Storage Synchronization Agent:** Periodically (e.g., daily after report generation) backs up the SQLite database and generated reports to Google Cloud Storage.\n\n```mermaid\ngraph TD\n    A[GitHub Actions Cron Trigger] --> B(Orchestrator Script);\n    B --> C{Fetch Public API Data};\n    C --> D{Process Data & Enrich with PydanticAI/Gemini/Search};\n    D --> E{Predict Patterns};\n    E --> F{Store Prediction in SQLite};\n    B --> G{Fetch Actuals for Past Predictions};\n    G --> H{Evaluate Past Prediction Accuracy};\n    H --> F;\n    F & D & H --> I{Generate PDF Report};\n    I --> J{Email Report to Subscribers};\n    F --> K{Sync SQLite DB to GCS};\n    I --> L{Upload PDF Report to GCS};\n```\n\n## 4. Tech Stack\n\n- **Programming Language:** Python 3.12+\n- **Data Validation & Settings:** Pydantic (v2.x)\n- **LLM & Search Integration:** PydanticAI\n- **Database:** SQLite (with SQLAlchemy 2.0.x for ORM and Alembic for migrations)\n- **Data Manipulation & Analysis:** Pandas (v2.x), NumPy\n- **Machine Learning/Statistics:** Scikit-learn (or other relevant libraries like Statsmodels, TensorFlow/PyTorch for more complex models)\n- **PDF Generation:** WeasyPrint (recommended), ReportLab\n- **Emailing:** `smtplib`, `email.mime` (Python standard library)\n- **HTTP Requests:** `httpx` (for asynchronous API calls)\n- **Cloud Storage:** Google Cloud Storage (`google-cloud-storage` library)\n- **Automation/CI/CD:** GitHub Actions\n- **Dependency Management:** Poetry (recommended) or PDM\n- **Testing:** `pytest`, `pytest-cov`\n- **Linting/Formatting:** Ruff\n- **Environment Variables:** `python-dotenv` (for local development)\n\n## 5. Prerequisites\n\n- Python 3.12 or later.\n- Poetry (or PDM) installed globally.\n- Google Cloud Platform (GCP) account with a GCS bucket created.\n- GCP credentials configured for application (e.g., via Application Default Credentials or a service account JSON key).\n- API keys for any public data sources and for Gemini (Google AI Studio).\n- SMTP server credentials if using a custom SMTP server for emails.\n\n## 6. Setup & Installation\n\n1.  **Clone the Repository:**\n    ```bash\n    git clone https://github.com/HappyPathway/smart-invest.git\n    cd smart-invest\n    ```\n\n2.  **Install Dependencies using Poetry:**\n    ```bash\n    poetry install\n    ```\n    *(If using PDM, use `pdm install`)*\n\n3.  **Set Up Environment Variables:**\n    Copy the `.env.example` file to `.env` and fill in the required values:\n    ```bash\n    cp .env.example .env\n    # Open .env and add your API keys, GCS details, DB URL, etc.\n    ```\n    Key variables in `.env` (refer to `src/smart_invest/core/config.py` for all settings):\n    - `DATABASE_URL`: e.g., `sqlite+aiosqlite:///./smart_invest.db`\n    - `GCS_BUCKET_NAME`: Your GCS bucket name.\n    - `GOOGLE_APPLICATION_CREDENTIALS`: Path to your GCS service account key file (if not using ADC).\n    - `GEMINI_API_KEY`: Your API key for Gemini.\n    - `SUBSCRIBER_EMAILS`: Comma-separated list of email addresses.\n    - `SMTP_HOST`, `SMTP_PORT`, `SMTP_USER`, `SMTP_PASSWORD`, `EMAIL_SENDER` (if applicable).\n    - Any other API keys for data sources.\n\n4.  **Initialize Database & Run Migrations:**\n    The application will use Alembic for database migrations.\n    ```bash\n    poetry run alembic upgrade head\n    ```\n\n## 7. Running the Application\n\n### Local Execution\n\nTo run the main application pipeline locally (e.g., for a single execution of the daily job):\n```bash\npoetry run python src/smart_invest/main.py\n```\n\nSpecific tasks or agents might be runnable individually for development or debugging purposes (details to be added as CLI commands are developed, e.g., using Typer or Click).\n\n### GitHub Actions Workflow\n\nThe application is designed to run as a cron job via GitHub Actions. The workflow is defined in `.github/workflows/daily_run.yml`.\nThis workflow will typically:\n1.  Checkout the code.\n2.  Set up Python and install dependencies (cached for speed).\n3.  Set up GCS authentication using secrets.\n4.  Execute the main application script (`src/smart_invest/main.py`).\n5.  Handle any artifacts (e.g., logs, reports if not directly uploaded by the script).\n\n## 8. Configuration\n\nApplication configuration is managed via environment variables and Pydantic's `BaseSettings` located in `src/smart_invest/core/config.py`.\nSee `.env.example` for a template of required environment variables.\n\n## 9. Project Structure (Recommended)\n\n```\nsmart-invest/\n\u251c\u2500\u2500 .github/                    # GitHub Actions workflows\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 daily_run.yml\n\u251c\u2500\u2500 .vscode/                    # VS Code settings (launch.json, settings.json)\n\u251c\u2500\u2500 data/                       # Local data files (e.g., SQLite DB, temporary files)\n\u2502   \u2514\u2500\u2500 smart_invest.db\n\u251c\u2500\u2500 reports/                    # Locally generated PDF reports (before GCS upload)\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 smart_invest/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 main.py                 # Main script, orchestrator\n\u2502       \u251c\u2500\u2500 core/\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 config.py           # Pydantic settings\n\u2502       \u2502   \u2514\u2500\u2500 logging_config.py   # Logging setup\n\u2502       \u251c\u2500\u2500 apis/                   # Clients for external data APIs\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u2514\u2500\u2500 public_api_client.py\n\u2502       \u251c\u2500\u2500 analysis/               # Data processing, PydanticAI integration\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u2514\u2500\u2500 analyzer.py\n\u2502       \u251c\u2500\u2500 prediction/             # Pattern prediction models and logic\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u2514\u2500\u2500 predictor.py\n\u2502       \u251c\u2500\u2500 reporting/              # PDF generation and emailing\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 report_generator.py\n\u2502       \u2502   \u251c\u2500\u2500 email_service.py\n\u2502       \u2502   \u2514\u2500\u2500 templates/          # HTML templates for PDF reports\n\u2502       \u251c\u2500\u2500 storage/                # SQLite and GCS interaction logic\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 db_manager.py       # SQLAlchemy session, CRUD operations\n\u2502       \u2502   \u2514\u2500\u2500 gcs_manager.py\n\u2502       \u251c\u2500\u2500 database/               # SQLAlchemy models and Alembic migrations\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 models.py\n\u2502       \u2502   \u2514\u2500\u2500 alembic/\n\u2502       \u2502       \u2514\u2500\u2500 versions/\n\u2502       \u2502   \u2514\u2500\u2500 alembic.ini\n\u2502       \u2514\u2500\u2500 evaluation/             # Prediction self-grading logic\n\u2502           \u251c\u2500\u2500 __init__.py\n\u2502           \u2514\u2500\u2500 evaluator.py\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py               # Pytest fixtures\n\u2502   \u251c\u2500\u2500 test_analysis.py\n\u2502   \u2514\u2500\u2500 ...                     # Other test files\n\u251c\u2500\u2500 .env.example                # Example environment variables\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 poetry.lock\n\u251c\u2500\u2500 pyproject.toml              # Poetry/PDM project configuration\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 alembic.ini                 # Top-level Alembic config (can point to src/...)\n```\n\n## 10. Key Modules/Components (Illustrative)\n\n- **`src/smart_invest/main.py`**: Entry point for the application, orchestrates the workflow.\n- **`src/smart_invest/core/config.py`**: Defines Pydantic models for application settings, loaded from environment variables.\n- **`src/smart_invest/apis/`**: Modules for interacting with various external data APIs.\n- **`src/smart_invest/analysis/analyzer.py`**: Handles data transformation, cleaning, and integration with PydanticAI for querying Gemini/Google Search.\n- **`src/smart_invest/prediction/predictor.py`**: Implements logic for pattern prediction using statistical or ML models.\n- **`src/smart_invest/database/models.py`**: Contains SQLAlchemy ORM models for database tables (e.g., predictions, historical data).\n- **`src/smart_invest/storage/db_manager.py`**: Manages database sessions and CRUD operations.\n- **`src/smart_invest/storage/gcs_manager.py`**: Handles interactions with Google Cloud Storage (uploading/downloading database backups and reports).\n- **`src/smart_invest/reporting/report_generator.py`**: Generates PDF reports from analyzed data and predictions.\n- **`src/smart_invest/reporting/email_service.py`**: Sends generated PDF reports to subscribers.\n- **`src/smart_invest/evaluation/evaluator.py`**: Contains logic to assess the accuracy of past predictions against actual outcomes.\n\n## 11. Contributing\n\nContributions are welcome! Please follow these steps:\n1.  Fork the repository.\n2.  Create a new branch (`git checkout -b feature/your-feature-name`).\n3.  Make your changes and commit them (`git commit -m 'Add some feature'`).\n4.  Ensure your code passes linting and tests (`poetry run ruff check .`, `poetry run ruff format .`, `poetry run pytest`).\n5.  Push to the branch (`git push origin feature/your-feature-name`).\n6.  Open a Pull Request.\n\nPlease ensure your code is well-documented and includes relevant tests.\n\n## 12. License\n\nThis project is licensed under the MIT License - see the `LICENSE` file for details (To be added - assuming MIT for now).\n\n```\n",
  "best_practices": [
    "Modular Design: Structure the application into well-defined, reusable modules for data fetching, analysis, prediction, reporting, and storage to enhance maintainability and testability.",
    "Data Validation with Pydantic: Utilize Pydantic extensively for validating API responses, configuration data, and internal data structures, ensuring data integrity throughout the application.",
    "Robust Error Handling & Logging: Implement comprehensive try-except blocks for error handling and use structured logging (e.g., Python's `logging` module) to record application behavior, errors, and important events for easier debugging and monitoring.",
    "Configuration Management: Externalize all configurations (API keys, database URLs, email settings, GCS paths) using environment variables and `.env` files, managed securely with Pydantic's `BaseSettings`.",
    "Automated Testing: Develop a comprehensive test suite using `pytest`, including unit tests for individual functions/modules and integration tests for workflows like data processing, prediction logic, and API interactions. Aim for high test coverage.",
    "CI/CD with GitHub Actions: Automate the entire development lifecycle, including linting, formatting, testing, building, and the scheduled execution of the data analysis and reporting job using GitHub Actions.",
    "Modern Dependency Management: Employ Poetry or PDM for robust dependency management, ensuring reproducible builds and a clean project environment.",
    "Asynchronous Operations for I/O: Leverage `asyncio` along with `httpx` for non-blocking I/O operations, especially when fetching data from multiple external APIs, to improve performance and responsiveness.",
    "Database Schema Management: Use Alembic for managing SQLAlchemy database migrations, allowing for version-controlled and systematic updates to the SQLite database schema.",
    "Secure Credential Management: Store and manage sensitive information like API keys and GCS credentials securely using GitHub Secrets for Actions and a secure method for local development (e.g., environment variables, Doppler, or HashiCorp Vault). Avoid hardcoding credentials."
  ],
  "suggested_extensions": [
    "ms-python.python",
    "ms-python.pylance",
    "charliermarsh.ruff",
    "eamodio.gitlens",
    "ms-azuretools.vscode-docker",
    "streetsidesoftware.code-spell-checker",
    "visualstudioexptteam.vscodeintellicode",
    "redhat.vscode-yaml",
    "esbenp.prettier-vscode"
  ],
  "documentation_source": [
    "Python Official Documentation: https://docs.python.org/3/",
    "Pydantic Documentation: https://docs.pydantic.dev/latest/",
    "PydanticAI Documentation: https://pydantic.github.io/pydantic-ai/",
    "SQLAlchemy Documentation (v2.0): https://docs.sqlalchemy.org/en/20/",
    "Alembic Documentation: https://alembic.sqlalchemy.org/en/latest/",
    "Pandas Documentation: https://pandas.pydata.org/pandas-docs/stable/",
    "WeasyPrint Documentation (for PDF generation): https://weasyprint.org/",
    "ReportLab User Guide (alternative for PDF generation): https://www.reportlab.com/docs/reportlab-userguide.pdf",
    "GitHub Actions Documentation: https://docs.github.com/en/actions",
    "Google Cloud Storage Client Libraries for Python: https://cloud.google.com/python/docs/reference/storage/latest",
    "HTTPX Documentation (for async HTTP requests): https://www.python-httpx.org/",
    "Requests Documentation (for sync HTTP requests): https://requests.readthedocs.io/en/latest/",
    "Scikit-learn Documentation: https://scikit-learn.org/stable/",
    "Poetry Documentation (Dependency Management): https://python-poetry.org/docs/",
    "PDM Documentation (Alternative Dependency Management): https://pdm-project.org/latest/",
    "Ruff Linter/Formatter Documentation: https://docs.astral.sh/ruff/"
  ],
  "copilot_instructions": "# GitHub Copilot Instructions for smart-invest\n\n## Project Context\n\n# Project Prompt\n\n\n## Best Practices\n\nNo best practices provided.\n\n\n## Recommended VS Code Extensions\n\nNo extensions suggested.\n\n\n## Documentation Sources\n\nNo documentation sources provided.\n\n\n\n\n## Best Practices\n\n\n- Modular Design: Structure the application into well-defined, reusable modules for data fetching, analysis, prediction, reporting, and storage to enhance maintainability and testability.\n\n- Data Validation with Pydantic: Utilize Pydantic extensively for validating API responses, configuration data, and internal data structures, ensuring data integrity throughout the application.\n\n- Robust Error Handling & Logging: Implement comprehensive try-except blocks for error handling and use structured logging (e.g., Python's `logging` module) to record application behavior, errors, and important events for easier debugging and monitoring.\n\n- Configuration Management: Externalize all configurations (API keys, database URLs, email settings, GCS paths) using environment variables and `.env` files, managed securely with Pydantic's `BaseSettings`.\n\n- Automated Testing: Develop a comprehensive test suite using `pytest`, including unit tests for individual functions/modules and integration tests for workflows like data processing, prediction logic, and API interactions. Aim for high test coverage.\n\n- CI/CD with GitHub Actions: Automate the entire development lifecycle, including linting, formatting, testing, building, and the scheduled execution of the data analysis and reporting job using GitHub Actions.\n\n- Modern Dependency Management: Employ Poetry or PDM for robust dependency management, ensuring reproducible builds and a clean project environment.\n\n- Asynchronous Operations for I/O: Leverage `asyncio` along with `httpx` for non-blocking I/O operations, especially when fetching data from multiple external APIs, to improve performance and responsiveness.\n\n- Database Schema Management: Use Alembic for managing SQLAlchemy database migrations, allowing for version-controlled and systematic updates to the SQLite database schema.\n\n- Secure Credential Management: Store and manage sensitive information like API keys and GCS credentials securely using GitHub Secrets for Actions and a secure method for local development (e.g., environment variables, Doppler, or HashiCorp Vault). Avoid hardcoding credentials.\n\n\n\n\n## Recommended VS Code Extensions\n\n\n- ms-python.python\n\n- ms-python.pylance\n\n- charliermarsh.ruff\n\n- eamodio.gitlens\n\n- ms-azuretools.vscode-docker\n\n- streetsidesoftware.code-spell-checker\n\n- visualstudioexptteam.vscodeintellicode\n\n- redhat.vscode-yaml\n\n- esbenp.prettier-vscode\n\n\n\n\n## Documentation Sources\n\n\n- Python Official Documentation: https://docs.python.org/3/\n\n- Pydantic Documentation: https://docs.pydantic.dev/latest/\n\n- PydanticAI Documentation: https://pydantic.github.io/pydantic-ai/\n\n- SQLAlchemy Documentation (v2.0): https://docs.sqlalchemy.org/en/20/\n\n- Alembic Documentation: https://alembic.sqlalchemy.org/en/latest/\n\n- Pandas Documentation: https://pandas.pydata.org/pandas-docs/stable/\n\n- WeasyPrint Documentation (for PDF generation): https://weasyprint.org/\n\n- ReportLab User Guide (alternative for PDF generation): https://www.reportlab.com/docs/reportlab-userguide.pdf\n\n- GitHub Actions Documentation: https://docs.github.com/en/actions\n\n- Google Cloud Storage Client Libraries for Python: https://cloud.google.com/python/docs/reference/storage/latest\n\n- HTTPX Documentation (for async HTTP requests): https://www.python-httpx.org/\n\n- Requests Documentation (for sync HTTP requests): https://requests.readthedocs.io/en/latest/\n\n- Scikit-learn Documentation: https://scikit-learn.org/stable/\n\n- Poetry Documentation (Dependency Management): https://python-poetry.org/docs/\n\n- PDM Documentation (Alternative Dependency Management): https://pdm-project.org/latest/\n\n- Ruff Linter/Formatter Documentation: https://docs.astral.sh/ruff/\n\n\n\n\n## Project-Specific Guidelines\n\n\n- Use asynchronous programming with `asyncio` and `httpx` for efficient data fetching.\n\n- Implement robust error handling and logging throughout the application.\n\n- Employ Pydantic for rigorous data validation at all stages.\n\n- Structure the code into well-defined modules for maintainability.\n\n- Utilize Alembic for database schema management.\n\n- Write comprehensive unit and integration tests using `pytest`.\n\n- Configure GitHub Actions for automated testing, building, and deployment.\n\n- Securely manage API keys and credentials using GitHub Secrets.\n\n- Prioritize code readability and maintainability.\n\n- Follow PEP 8 style guidelines and use Ruff for linting and formatting.\n\n\n\n\n## Helpful Context\n\n\n- Python Official Documentation: https://docs.python.org/3/\n\n- Pydantic Documentation: https://docs.pydantic.dev/latest/\n\n- PydanticAI Documentation: https://pydantic.github.io/pydantic-ai/\n\n- SQLAlchemy Documentation (v2.0): https://docs.sqlalchemy.org/en/20/\n\n- Alembic Documentation: https://alembic.sqlalchemy.org/en/latest/\n\n- Pandas Documentation: https://pandas.pydata.org/pandas-docs/stable/\n\n- WeasyPrint Documentation (for PDF generation): https://weasyprint.org/\n\n- ReportLab User Guide (alternative for PDF generation): https://www.reportlab.com/docs/reportlab-userguide.pdf\n\n- GitHub Actions Documentation: https://docs.github.com/en/actions\n\n- Google Cloud Storage Client Libraries for Python: https://cloud.google.com/python/docs/reference/storage/latest\n\n- HTTPX Documentation (for async HTTP requests): https://www.python-httpx.org/\n\n- Requests Documentation (for sync HTTP requests): https://requests.readthedocs.io/en/latest/\n\n- Scikit-learn Documentation: https://scikit-learn.org/stable/\n\n- Poetry Documentation (Dependency Management): https://python-poetry.org/docs/\n\n- PDM Documentation (Alternative Dependency Management): https://pdm-project.org/latest/\n\n- Ruff Linter/Formatter Documentation: https://docs.astral.sh/ruff/\n\n",
  "project_type": "Automated Data Analysis and Reporting System",
  "programming_language": "Python"
}